import logging
import queue
import uuid
from datetime import datetime, timedelta

import mock
import pytest
import sqlalchemy.orm
from sqlalchemy import not_

from exodus_gw import models, worker
from exodus_gw.models import Item, Publish
from exodus_gw.models.path import PublishedPath
from exodus_gw.settings import load_settings

pytestmark = pytest.mark.usefixtures("mock_boto3_client")

NOW_UTC = datetime.utcnow()


def _task(publish_id):
    return models.CommitTask(
        id="8d8a4692-c89b-4b57-840f-b3f0166148d2",
        publish_id=publish_id,
        state="NOT_STARTED",
        deadline=NOW_UTC + timedelta(hours=2),
    )


def add_kickstart(publish: Publish):
    """Adds some kickstart items onto a publish."""
    publish.items.extend(
        [
            models.Item(
                web_uri="/content/testproduct/1/kickstart/extra_files.json",
                object_key="cee38a35950f3f9465378b1548c4495882da0bfbe217999add63cb3a8e2c4d75",
                publish_id=publish.id,
                updated=datetime(2023, 10, 4, 3, 52, 2),
            ),
            models.Item(
                web_uri="/content/testproduct/1/kickstart/EULA",
                object_key="6c92384cdbf1a8c448278aaffaf7d8c3f048749e201d504ffaab07d85f6b1a03",
                publish_id=publish.id,
                updated=datetime(2023, 10, 4, 3, 52, 2),
            ),
            models.Item(
                web_uri="/content/testproduct/1/kickstart/Packages/example.rpm",
                object_key="88a2831543aaca1355a725ad2f5969c7a180643beddfe94281343a2ba361c979",
                publish_id=publish.id,
                updated=datetime(2023, 10, 4, 3, 52, 2),
            ),
        ]
    )


@mock.patch("exodus_gw.worker.publish.AutoindexEnricher.run")
@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
@mock.patch("exodus_gw.worker.publish.Flusher")
def test_commit(
    mock_flusher,
    mock_write_batch,
    mock_get_message,
    mock_autoindex_run,
    fake_publish,
    db: sqlalchemy.orm.Session,
    caplog,
):
    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )
    # Simulate successful write of items by write_batch.
    mock_write_batch.return_value = True

    # Let this test cover kickstart items.
    add_kickstart(fake_publish)

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    # Check PublishedPaths before doing the commit so we can tell what was added.
    pp_ids = [pp.id for pp in db.query(PublishedPath).all()]

    worker.commit(str(fake_publish.id), fake_publish.env, str(NOW_UTC))

    # It should've set task state to COMPLETE.
    db.refresh(task)
    assert task.state == "COMPLETE"
    # It should've set publish state to COMMITTED.
    db.refresh(fake_publish)
    assert fake_publish.state == "COMMITTED"

    # It should've called write_batch for items and entry point items.
    mock_write_batch.assert_has_calls(
        calls=[
            mock.call(mock.ANY, delete=False),
            mock.call(mock.ANY, delete=False),
        ]
    )

    # It should've written all items.
    assert "Commit may be incomplete" not in caplog.text

    # Flusher should have been passed the expected paths,
    # and then run()
    calls = mock_flusher.mock_calls
    flusher_args = calls[0][1]
    assert flusher_args[0] == [
        # Note that this does not include paths after alias resolution,
        # because Flusher does alias resolution itself internally
        # (tested elsewhere)
        # Note that the default phase2_patterns cause all non-RPM kickstart
        # files to be flushed.
        "/content/testproduct/1/kickstart/EULA",
        "/content/testproduct/1/kickstart/extra_files.json",
        "/content/testproduct/1/repo/",
        "/content/testproduct/1/repo/repomd.xml",
    ]
    mock_flusher().run.assert_called_once()

    # It should've invoked the autoindex enricher
    mock_autoindex_run.assert_called_once()

    # It should've added rows into PublishedPaths
    published_paths = (
        db.query(PublishedPath)
        .filter(not_(PublishedPath.id.in_(pp_ids)))
        .all()
    )
    assert sorted([(pp.env, pp.web_uri) for pp in published_paths]) == sorted(
        [
            # Note that both sides of the 1 alias are recorded, including
            # beyond the RHUI alias.
            (
                "test",
                "/content/product_duplicate/1/kickstart/EULA",
            ),
            (
                "test",
                "/content/product_duplicate/1/kickstart/extra_files.json",
            ),
            (
                "test",
                "/content/product_duplicate/1/repo/",
            ),
            (
                "test",
                "/content/product_duplicate/1/repo/repomd.xml",
            ),
            (
                "test",
                "/content/testproduct/1.1.0/kickstart/extra_files.json",
            ),
            (
                "test",
                "/content/testproduct/1/kickstart/extra_files.json",
            ),
            (
                "test",
                "/content/testproduct/rhui/1.1.0/kickstart/extra_files.json",
            ),
            (
                "test",
                "/content/testproduct/rhui/1/kickstart/extra_files.json",
            ),
            (
                "test",
                "/content/testproduct/1.1.0/kickstart/EULA",
            ),
            (
                "test",
                "/content/testproduct/1/kickstart/EULA",
            ),
            (
                "test",
                "/content/testproduct/rhui/1.1.0/kickstart/EULA",
            ),
            (
                "test",
                "/content/testproduct/rhui/1/kickstart/EULA",
            ),
            ("test", "/content/testproduct/1/repo/"),
            ("test", "/content/testproduct/1.1.0/repo/"),
            ("test", "/content/testproduct/1/repo/repomd.xml"),
            ("test", "/content/testproduct/1.1.0/repo/repomd.xml"),
            ("test", "/content/testproduct/rhui/1/repo/"),
            ("test", "/content/testproduct/rhui/1/repo/repomd.xml"),
            ("test", "/content/testproduct/rhui/1.1.0/repo/"),
            ("test", "/content/testproduct/rhui/1.1.0/repo/repomd.xml"),
        ]
    )


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
def test_commit_expired_task(mock_get_message, fake_publish, db, caplog):
    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )

    # Expire the task
    task.deadline = NOW_UTC - timedelta(hours=5)

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've logged message.
    assert (
        "Task 8d8a4692-c89b-4b57-840f-b3f0166148d2 expired at %s"
        % task.deadline
        in caplog.text
    )
    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"
    # It should've set publish state to FAILED.
    db.refresh(fake_publish)
    assert fake_publish.state == "FAILED"


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_write_items_fail(
    mock_write_batch, mock_get_message, fake_publish, db, caplog
):
    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )
    # Simulate failed write of items.
    mock_write_batch.side_effect = [RuntimeError(), None]

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've failed write_batch and recalled to roll back.
    mock_write_batch.assert_has_calls(
        calls=[
            mock.call(mock.ANY, delete=False),
            mock.call(mock.ANY, delete=True),
        ],
        any_order=False,
    )
    # It should've logged messages.
    assert "Exception while submitting batch write(s)" in caplog.text
    assert (
        "Task 8d8a4692-c89b-4b57-840f-b3f0166148d2 encountered an error"
        in caplog.text
    )
    assert "Rolling back 2 item(s) due to error" in caplog.text
    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"
    # It should've set publish state to FAILED.
    db.refresh(fake_publish)
    assert fake_publish.state == "FAILED"


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
@mock.patch("exodus_gw.worker.publish.Flusher")
def test_commit_write_entry_point_items_fail(
    mock_flusher, mock_write_batch, mock_get_message, fake_publish, db, caplog
):
    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )
    # Simulate successful write of items, failed write of entry point items
    # and then successful deletion of items.
    mock_write_batch.side_effect = [None, RuntimeError(), None]

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've called write_batch for items, entry point items
    # and then deletion of written items.
    mock_write_batch.assert_has_calls(
        calls=[
            mock.call(mock.ANY, delete=False),
            mock.call(mock.ANY, delete=False),
            mock.call(mock.ANY, delete=True),
        ],
        any_order=False,
    )
    # It should've logged messages.
    assert "Exception while submitting batch write(s)" in caplog.text
    assert "Rolling back 4 item(s) due to error" in caplog.text

    # Flush should have occurred during rollback also
    calls = mock_flusher.mock_calls
    flusher_args = calls[0][1]
    assert flusher_args[0] == [
        "/content/testproduct/1/repo/",
        "/content/testproduct/1/repo/repomd.xml",
    ]
    mock_flusher().run.assert_called_once()

    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"
    # It should've set publish state to FAILED.
    db.refresh(fake_publish)
    assert fake_publish.state == "FAILED"


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_completed_task(mock_write_batch, mock_get_message, db, caplog):
    # Construct task that would be generated by caller.
    task = _task(publish_id="123e4567-e89b-12d3-a456-426614174000")
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": task.publish_id}
    )

    db.add(task)
    # Simulate prior completion of task.
    task.state = "COMPLETE"
    db.commit()

    worker.commit(task.publish_id, "test", NOW_UTC)

    # It should've logged a warning message.
    assert "Task %s in unexpected state, 'COMPLETE'" % task.id in caplog.text
    # It should not have called write_batch.
    mock_write_batch.assert_not_called()


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_completed_publish(
    mock_write_batch, mock_get_message, fake_publish, db, caplog
):
    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )

    db.add(task)
    db.add(fake_publish)
    # Simulate prior completion of publish.
    fake_publish.state = "COMPLETE"
    db.commit()

    worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've logged a warning message.
    assert (
        "Publish %s in unexpected state, 'COMPLETE'" % fake_publish.id
        in caplog.text
    )
    # It should not have called write_batch.
    mock_write_batch.assert_not_called()


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_empty_publish(
    mock_write_batch, mock_get_message, fake_publish, db, caplog
):
    caplog.set_level(logging.DEBUG, "exodus-gw")

    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_message.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )

    # Empty the publish.
    fake_publish.items = []

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've logged a message.
    assert "No items to write for publish %s" % fake_publish.id in caplog.text
    # It should've set task state to COMPLETE.
    db.refresh(task)
    assert task.state == "COMPLETE"
    # It should've set publish state to COMMITTED.
    db.refresh(fake_publish)
    assert fake_publish.state == "COMMITTED"
    # It should not have called write_batch.
    mock_write_batch.assert_not_called()


@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_write_queue_unfinished(
    mock_write_batch, mock_get_msg, fake_publish, db, caplog
):
    """It's possible for queues to retain items due to worker errors."""
    caplog.set_level(logging.DEBUG, "exodus-gw")

    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_msg.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )
    mock_write_batch.return_value = None

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    settings = load_settings()
    settings.write_max_workers = 1
    settings.write_queue_timeout = 1
    commit_obj = worker.publish.CommitPhase2(
        fake_publish.id, fake_publish.env, NOW_UTC, task.id, settings
    )
    bw = worker.publish._BatchWriter(
        commit_obj.dynamodb,
        settings,
        len(fake_publish.items),
        "test write items",
    )
    # Simulate worker issue preventing write_batches from executing and
    # getting items from the queue.
    bw.write_batches = mock.MagicMock()

    with mock.patch("exodus_gw.worker.publish.CommitPhase2") as patched_commit:
        patched_commit.return_value = commit_obj
        with mock.patch("exodus_gw.worker.publish._BatchWriter") as patched_bw:
            patched_bw.return_value = bw
            with pytest.raises(RuntimeError):
                worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've logged messages.
    assert "Exception while submitting batch write(s)" in caplog.text
    assert "Commit incomplete, queue not empty" in caplog.text
    assert (
        "Task 8d8a4692-c89b-4b57-840f-b3f0166148d2 encountered an error"
        in caplog.text
    )
    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"
    # It should've set publish state to FAILED.
    db.refresh(fake_publish)
    assert fake_publish.state == "FAILED"


@mock.patch("queue.Queue.put")
@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_write_queue_full(
    mock_write_batch, mock_get_msg, mock_q_put, fake_publish, db, caplog
):
    """It's possible to hit queue.put timeout
    (e.g., due to slow processing/get), causing queue.Full error.
    """
    caplog.set_level(logging.DEBUG, "exodus-gw")

    # Construct task that would be generated by caller.
    task = _task(fake_publish.id)
    # Construct dramatiq message that would be generated by caller.
    mock_get_msg.return_value = mock.MagicMock(
        message_id=task.id, kwargs={"publish_id": fake_publish.id}
    )
    mock_write_batch.return_value = None

    db.add(fake_publish)
    db.add(task)
    # Caller would've set publish state to COMMITTING.
    fake_publish.state = "COMMITTING"
    db.commit()

    # Simulate some issue causing timeouts after first put.
    mock_q_put.side_effect = [None, queue.Full(), queue.Full(), queue.Full()]

    settings = load_settings()
    settings.write_max_workers = 1
    settings.write_queue_timeout = 1
    commit_obj = worker.publish.CommitPhase2(
        fake_publish.id, fake_publish.env, NOW_UTC, task.id, settings
    )

    with mock.patch("exodus_gw.worker.publish.CommitPhase2") as patched_commit:
        patched_commit.return_value = commit_obj
        with pytest.raises(queue.Full):
            worker.commit(str(fake_publish.id), fake_publish.env, NOW_UTC)

    # It should've logged messages.
    assert "Exception while submitting batch write(s)" in caplog.text
    assert (
        "Task 8d8a4692-c89b-4b57-840f-b3f0166148d2 encountered an error"
        in caplog.text
    )
    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"
    # It should've set publish state to FAILED.
    db.refresh(fake_publish)
    assert fake_publish.state == "FAILED"


@mock.patch("exodus_gw.worker.publish.AutoindexEnricher.run")
@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_phase1(
    mock_write_batch,
    mock_get_message,
    mock_autoindex_run,
    fake_publish: Publish,
    db: sqlalchemy.orm.Session,
    caplog: pytest.LogCaptureFixture,
):
    """Verifies specific behaviors of a phase1 commit, namely:

    - does not include phase2 items (e.g. entrypoints)
    - does not include items with unresolved links
    - does not include autoindex
    - does not move the publish into a terminal state
    - only processes dirty items (and marks them as dirty)
    """

    task = _task(fake_publish.id)
    mock_get_message.return_value = mock.Mock(
        spec=["message_id"],
        message_id=task.id,
    )

    # Force the publish to include a link item which hasn't been
    # resolved to a proper object_key yet.
    fake_publish.items.append(
        models.Item(
            web_uri="/some/path/to/link-src",
            link_to="/some/link-dest",
            publish_id=fake_publish.id,
            updated=datetime(2023, 10, 4, 3, 52, 0),
        )
    )

    # Let this test cover kickstart items.
    add_kickstart(fake_publish)

    db.add(fake_publish)
    db.add(task)

    # Committing and refreshing to ensure any commit-time defaults are applied.
    db.commit()
    db.refresh(fake_publish)
    db.refresh(task)

    # All the items should initially be dirty.
    assert [i.dirty for i in fake_publish.items] == [True] * len(
        fake_publish.items
    )

    # Let's say that DynamoDB write initially fails.
    mock_write_batch.side_effect = RuntimeError("simulated error")

    # Try the commit.
    with pytest.raises(RuntimeError):
        worker.commit(
            str(fake_publish.id),
            fake_publish.env,
            NOW_UTC.isoformat(),
            commit_mode="phase1",
        )

    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"

    # But it should NOT have updated the publish state.
    db.refresh(fake_publish)
    assert fake_publish.state == "PENDING"

    # Allow DynamoDB write to succeed, and try again.
    task.state = "PENDING"
    db.commit()
    mock_write_batch.side_effect = None
    mock_write_batch.return_value = True

    # Do the commit.
    worker.commit(
        str(fake_publish.id),
        fake_publish.env,
        NOW_UTC.isoformat(),
        commit_mode="phase1",
    )

    # It should've set task state to COMPLETE.
    db.refresh(task)
    assert task.state == "COMPLETE"

    # But it should still NOT have updated the publish state.
    db.refresh(fake_publish)
    assert fake_publish.state == "PENDING"

    # It should only have processed the phase1 items (e.g. not entry points),
    # which should be reflected in the 'dirty' state:
    assert sorted(
        [{"web_uri": i.web_uri, "dirty": i.dirty} for i in fake_publish.items],
        key=lambda d: d["web_uri"],
    ) == sorted(
        [
            {"dirty": False, "web_uri": "/other/path"},
            {"dirty": False, "web_uri": "/some/path"},
            # kickstart content:
            # - EULA, though not an entrypoint, was forcibly delayed to phase2
            #   via phase2_patterns setting. And therefore is still 'dirty'.
            # - RPMs aren't matched by phase2_patterns and can still be
            #   processed in phase1.
            # - extra_files.json is an entrypoint and so is also delayed until
            #   phase2.
            {
                "dirty": True,
                "web_uri": "/content/testproduct/1/kickstart/EULA",
            },
            {
                "dirty": False,
                "web_uri": "/content/testproduct/1/kickstart/Packages/example.rpm",
            },
            {
                "dirty": True,
                "web_uri": "/content/testproduct/1/kickstart/extra_files.json",
            },
            # the unresolved link is not yet written and therefore remains dirty
            {"dirty": True, "web_uri": "/some/path/to/link-src"},
            # autoindex and repomd.xml are both entrypoints, not yet written,
            # and therefore remain dirty
            {
                "dirty": True,
                "web_uri": "/content/testproduct/1/repo/.__exodus_autoindex",
            },
            {
                "dirty": True,
                "web_uri": "/content/testproduct/1/repo/repomd.xml",
            },
        ],
        key=lambda d: str(d["web_uri"]),
    )

    # It should have told us how many it wrote and how many remain
    assert (
        "Phase 1: committed 3 items, phase 2: 4 items remaining" in caplog.text
    )

    # Let's do the same commit again...
    caplog.clear()
    task.state = "PENDING"
    db.commit()

    worker.commit(
        str(fake_publish.id),
        fake_publish.env,
        NOW_UTC.isoformat(),
        commit_mode="phase1",
    )

    # This time there should not have been any phase1 items processed at all,
    # as none of them were dirty.
    assert (
        "Phase 1: committed 0 items, phase 2: 4 items remaining" in caplog.text
    )

    # And it should NOT have invoked the autoindex enricher in either commit
    mock_autoindex_run.assert_not_called()


@mock.patch("exodus_gw.worker.publish.AutoindexEnricher.run")
@mock.patch("exodus_gw.worker.publish.CurrentMessage.get_current_message")
@mock.patch("exodus_gw.worker.publish.DynamoDB.write_batch")
def test_commit_missing_object_key(
    mock_write_batch,
    mock_get_message,
    mock_autoindex_run,
    fake_publish: Publish,
    db: sqlalchemy.orm.Session,
    caplog: pytest.LogCaptureFixture,
):
    """Commit raises an error if asked to commit an unresolved link."""

    task = _task(fake_publish.id)
    mock_get_message.return_value = mock.Mock(
        spec=["message_id"],
        message_id=task.id,
    )

    # Force the publish to include a link item which hasn't been
    # resolved to a proper object_key yet.
    fake_publish.items.append(
        models.Item(
            web_uri="/some/path/to/link-src",
            link_to="/some/link-dest",
            publish_id=fake_publish.id,
            updated=datetime(2023, 10, 4, 3, 52, 0),
        )
    )

    fake_publish.state = "COMMITTING"

    db.add(fake_publish)
    db.add(task)

    # Committing and refreshing to ensure any commit-time defaults are applied.
    db.commit()
    db.refresh(fake_publish)
    db.refresh(task)

    mock_write_batch.side_effect = None
    mock_write_batch.return_value = True

    # Do the commit.
    worker.commit(
        str(fake_publish.id),
        fake_publish.env,
        NOW_UTC.isoformat(),
        commit_mode="phase2",
    )

    # It should've set task state to FAILED.
    db.refresh(task)
    assert task.state == "FAILED"

    # It should've logged the reason why.
    assert "BUG: missing object_key for /some/path/to/link-src" in caplog.text
